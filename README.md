# Tensorflow-serving

TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. TensorFlow Serving makes it easy to deploy new algorithms and experiments, while keeping the same server architecture and APIs.

How do you use TensorFlow serving?
Train and serve a TensorFlow model with TensorFlow Serving
1. Table of contents.
2. Create your model. Import the Fashion MNIST dataset. Train and evaluate your model.
3. Save your model.
4. Examine your saved model.
5. Serve your model with TensorFlow Serving. Add TensorFlow Serving distribution URI as a package source: ...
6. Make a request to your model in TensorFlow Serving. Make REST requests.

We can use tensorflow serving for 3 task:-
1. To deploy single model with single version in production environment
2. To deploy single model with multiple version 
3. To deploy multiple model in the same environment
